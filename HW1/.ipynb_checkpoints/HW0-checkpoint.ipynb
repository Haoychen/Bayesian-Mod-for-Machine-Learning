{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'hw1_data_csv/'\n",
    "# Training data\n",
    "xtrn =pd.read_csv(path+'Xtrain.csv', header=None)\n",
    "ytrn =list(pd.read_csv(path+'ytrain.csv', header=None)[0])\n",
    "xtrn['y'] = ytrn\n",
    "\n",
    "# Reading test data\n",
    "xtst =pd.read_csv(path+'Xtest.csv', header=None)\n",
    "ytst =list(pd.read_csv(path+'ytest.csv', header=None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(object):\n",
    "    \n",
    "    def __init__(self, parameters):\n",
    "        self.parameters = parameters\n",
    "    \n",
    "    def posterior_predictive_distribution_y(self, y, y_new):\n",
    "        e, f = self.parameters[3:5]\n",
    "        if y_new == 1:\n",
    "            return (e + sum(y)) / (len(y) + e + f)\n",
    "        else:\n",
    "            return (f + len(y) - sum(y)) / (len(y) + e + f)\n",
    "    \n",
    "    def posterior_predictive_distribution_x(self, x, y, x_new, y_new):\n",
    "        a, b, c = self.parameters[0:3]\n",
    "        if y_new == 0:\n",
    "            posteriorX = 1\n",
    "            for feature_index in range(15):\n",
    "                x_train = list(x[x['y'] == 0][feature_index])\n",
    "                x_star = x_new[feature_index]\n",
    "                miu_star = sum(x_train) / (len(x_train) + 1 / a)\n",
    "                alpha = b + len(x_train) / 2\n",
    "                beta = c + 0.5 * (len(x_train) * np.var(x_train) + len(x_train) * ((sp.mean(x_train)) ** 2) / (1 + len(x_train)))\n",
    "                N_star = 1 / (len(x_train) + 1 / a)\n",
    "                value = sp.special.gamma(alpha + 0.5) / sp.special.gamma(alpha) * sp.sqrt(alpha / (beta * (N_star + 1)) / (sp.pi * 2 * alpha)) * sp.power(1 + ((alpha / (beta * (N_star + 1))) * ((x_star - miu_star) ** 2)) / (2 * alpha), - alpha - 0.5)          \n",
    "                posteriorX = posteriorX * value\n",
    "        else:\n",
    "            posteriorX = 1\n",
    "            for feature_index in range(15):\n",
    "                x_train = list(x[x['y'] == 1][feature_index])\n",
    "                x_star = x_new[feature_index]\n",
    "                miu_star = sum(x_train) / (len(x_train) + 1 / a)\n",
    "                alpha = b + len(x_train) / 2\n",
    "                beta = c + 0.5 * (len(x_train) * np.var(x_train) + len(x_train) * ((sp.mean(x_train)) ** 2) / (1 + len(x_train)))\n",
    "                N_star = 1 / (len(x_train) + 1 / a)\n",
    "                value = sp.special.gamma(alpha + 0.5) / sp.special.gamma(alpha) * sp.sqrt(alpha / (beta * (N_star + 1)) / (sp.pi * 2 * alpha)) * sp.power(1 + ((alpha / (beta * (N_star + 1))) * ((x_star - miu_star) ** 2)) / (2 * alpha), - alpha - 0.5)          \n",
    "                posteriorX = posteriorX * value\n",
    "        \n",
    "        return posteriorX\n",
    "                \n",
    "    def fit(self, x, y, x_new):\n",
    "        x_test = map(list, x_new.values)\n",
    "        y_test = []\n",
    "        for x_predict in x_test:\n",
    "            posterior_y_0 = self.posterior_predictive_distribution_x(x, y, x_predict, 0) * self.posterior_predictive_distribution_y(y, 0)\n",
    "            posterior_y_1 = self.posterior_predictive_distribution_x(x, y, x_predict, 1) * self.posterior_predictive_distribution_y(y, 1)\n",
    "            if posterior_y_0 >= posterior_y_1:\n",
    "                y_test.append(0)\n",
    "            else:\n",
    "                y_test.append(1)\n",
    "        return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = [1, 1, 1, 1, 1]\n",
    "classifier = NaiveBayesClassifier(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ^: 'numpy.float64' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a5e1300a7595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-5c9f78f3b11c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, x_new)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_predict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mposterior_y_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_predictive_distribution_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_predictive_distribution_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mposterior_y_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_predictive_distribution_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_predictive_distribution_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mposterior_y_0\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mposterior_y_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-5c9f78f3b11c>\u001b[0m in \u001b[0;36mposterior_predictive_distribution_x\u001b[0;34m(self, x, y, x_new, y_new)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mmiu_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mN_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN_star\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN_star\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_star\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmiu_star\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for ^: 'numpy.float64' and 'int'"
     ]
    }
   ],
   "source": [
    "y_test = classifier.fit(xtrn, ytrn, xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b322d5973384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating feature 0\n",
      "Evaluating feature 1\n",
      "Evaluating feature 2\n",
      "Evaluating feature 3\n",
      "Evaluating feature 4\n",
      "Evaluating feature 5\n",
      "Evaluating feature 6\n",
      "Evaluating feature 7\n",
      "Evaluating feature 8\n",
      "Evaluating feature 9\n",
      "Evaluating feature 10\n",
      "Evaluating feature 11\n",
      "Evaluating feature 12\n",
      "Evaluating feature 13\n",
      "Evaluating feature 14\n",
      "End\n",
      "Predicted    0    1\n",
      "Actual             \n",
      "0          903   79\n",
      "1          124  885\n",
      "Model accuracy is 0.898041185334\n",
      "1788/1991\n",
      "Three misclassified observations are:\n",
      "Plot and Summary for Observation 16\n",
      "0             -0.938335\n",
      "1             -0.920553\n",
      "Predicted             1\n",
      "Actual                0\n",
      "Prob_y0        0.495217\n",
      "Prob_y1        0.504783\n",
      "Incorrect             1\n",
      "Ambig        0.00478306\n",
      "Name: 16, dtype: object\n",
      "Plot and Summary for Observation 20\n",
      "0              -1.34739\n",
      "1               -1.3335\n",
      "Predicted             1\n",
      "Actual                0\n",
      "Prob_y0        0.497409\n",
      "Prob_y1        0.502591\n",
      "Incorrect             1\n",
      "Ambig        0.00259065\n",
      "Name: 20, dtype: object\n",
      "Plot and Summary for Observation 21\n",
      "0             -1.06885\n",
      "1            -0.995521\n",
      "Predicted            1\n",
      "Actual               0\n",
      "Prob_y0        0.48224\n",
      "Prob_y1        0.51776\n",
      "Incorrect            1\n",
      "Ambig        0.0177602\n",
      "Name: 21, dtype: object\n",
      "Three most ambiguous predictions are [  67 1118 1666]\n",
      "Plot and Summary for Observation 67\n",
      "0               -1.24314\n",
      "1               -1.24293\n",
      "Predicted              1\n",
      "Actual                 0\n",
      "Prob_y0         0.499958\n",
      "Prob_y1         0.500042\n",
      "Incorrect              1\n",
      "Ambig        4.18348e-05\n",
      "Name: 67, dtype: object\n",
      "Plot and Summary for Observation 67\n",
      "0               -1.24314\n",
      "1               -1.24293\n",
      "Predicted              1\n",
      "Actual                 0\n",
      "Prob_y0         0.499958\n",
      "Prob_y1         0.500042\n",
      "Incorrect              1\n",
      "Ambig        4.18348e-05\n",
      "Name: 67, dtype: object\n",
      "Plot and Summary for Observation 67\n",
      "0               -1.24314\n",
      "1               -1.24293\n",
      "Predicted              1\n",
      "Actual                 0\n",
      "Prob_y0         0.499958\n",
      "Prob_y1         0.500042\n",
      "Incorrect              1\n",
      "Ambig        4.18348e-05\n",
      "Name: 67, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Tue Sep 22 15:49:31 2015\n",
    "@author: franciscojavierarceo\n",
    "\"\"\"\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def plotNumber(q, x, rowval, data):\n",
    "    print 'Plot and Summary for Observation ' + str(rowval)\n",
    "    xtmp = np.array(x.iloc[rowval].T).reshape((15, 1))\n",
    "    x2 = np.dot(q, xtmp).reshape((28,28))\n",
    "    plt.imshow(x2, interpolation='nearest')\n",
    "    print data.iloc[rowval]\n",
    "    plt.savefig('Plot_Row%i.jpg'  % rowval)\n",
    "\n",
    "def PosteriorX(a, b, xtrn, xtst, ytrn, val):\n",
    "    sdx = np.std(np.hstack((xtrn,xtst)))    # This cleans it up a bit\n",
    "    tmpx = xtrn[np.where(ytrn==val)[0]]     # X given Y = j \n",
    "    xtrn_yj= tmpx / sdx                     # Scaling the xs\n",
    "    xbar = np.mean(xtrn_yj)                 # Conditional mean\n",
    "    n = float(xtrn_yj.shape[0])             # Number of observations\n",
    "    v = 2.0*b + n\n",
    "    mu_x = n*xbar/float((1/float(a)+n))\n",
    "    scale = 2.0 * float((a*n+a+1)) / float((v+a*n*v))\n",
    "    tout = (-(v+1.0)/2.0)*np.log(1.0+((xtst/sdx -mu_x)**2.0) / (scale*v))\n",
    "    return tout.reshape((len(xtst),1))\n",
    "\n",
    "def PrintAccuracy(pred, actual):\n",
    "    perf = pd.crosstab(pred,actual).values\n",
    "    print \"Model accuracy is \" + str( (perf[0][0] + perf[1][1])/float(len(pred)))\n",
    "    print str(perf[0][0] + perf[1][1]) +\"/\" + str(len(pred))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Specify the path of the data\n",
    "    path = 'hw1_data_csv/'\n",
    "    # Training data\n",
    "    xtrn =pd.read_csv(path+'Xtrain.csv', header=None)\n",
    "    ytrn =pd.read_csv(path+'ytrain.csv', header=None)\n",
    "    # Reading test data\n",
    "    xtst =pd.read_csv(path+'Xtest.csv', header=None)\n",
    "    ytst =pd.read_csv(path+'ytest.csv', header=None)\n",
    "    # Need Q to project data back into an image\n",
    "    Q = pd.read_csv(path+\"Q.csv\", header=None)\n",
    "\n",
    "    # Setting Hyper Parameters    \n",
    "    a,b,c,d,e,f = [1.0]*6\n",
    "    # Class priors\n",
    "    post_y1 = float((e + sum(ytrn==1)) / (len(ytrn)+e+f))\n",
    "    post_y0 = float((f + sum(ytrn==0)) / (len(ytrn)+e+f))\n",
    "    # Initializing the predictions to 0 -- so that I can just add them\n",
    "    pred_y1 = np.zeros((len(ytst),1))\n",
    "    pred_y0 = np.zeros((len(ytst),1))\n",
    "    k = xtst.shape[1]\n",
    "\n",
    "    for i in range(0, k):\n",
    "        print('Evaluating feature %i' % i)\n",
    "        post_y1x1 = PosteriorX(1, 1, xtrn[i], xtst[i], ytrn, 1) * post_y1\n",
    "        post_y0x0 = PosteriorX(1, 1, xtrn[i], xtst[i], ytrn, 0) * post_y0\n",
    "        pred_y1 = post_y1x1 + pred_y1\n",
    "        pred_y0 = post_y0x0 + pred_y0\n",
    "        if (i== k-1):\n",
    "            print \"End\"    \n",
    "\n",
    "    preds = pd.DataFrame(pred_y0)\n",
    "    preds['1'] = pred_y1\n",
    "    preds['Predicted'] = preds.idxmax(1)\n",
    "    preds['Actual'] = ytst\n",
    "\n",
    "    tmp = preds.ix[:,0]+preds.ix[:,1] # Normalizing to get the probabilities\n",
    "    preds['Prob_y0'] = 1.0- preds.ix[:,0]/tmp   # Have to do 1-x\n",
    "    preds['Prob_y1'] = 1.0- preds.ix[:,1]/tmp\n",
    "    preds['Incorrect'] = np.absolute(np.array(preds['Predicted'],dtype=int) -preds['Actual'])\n",
    "    preds['Ambig'] =  np.absolute(preds['Prob_y1']-0.5000 )\n",
    "\n",
    "    # Most ambiguous predictions are those with absolute value closest to 0.5    \n",
    "    x, y = preds.index, preds['Ambig']\n",
    "    top3 = preds['Ambig'].argsort()[0:3]\n",
    "\n",
    "    # Note, y = 0 means 4 and y = 1 means 9\n",
    "    print pd.crosstab(preds['Actual'],preds['Predicted'])\n",
    "    PrintAccuracy(preds['Actual'],preds['Predicted'])\n",
    "\n",
    "    incorrect= preds.index[preds['Incorrect']==1][0:3]\n",
    "    \n",
    "    print('Three misclassified observations are:')\n",
    "    for i in incorrect:\n",
    "        plotNumber(Q, xtrn, i ,preds)\n",
    "    \n",
    "    print(\"Three most ambiguous predictions are \" + str(top3.values))\n",
    "\n",
    "    for t3 in top3:\n",
    "        plotNumber(Q,xtrn,top3[0],preds)\n",
    "\n",
    "#------------------------------------\n",
    "# End \n",
    "#------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "a, b, c = [1, 1, 1]   \n",
    "x_train = list(xtrn[xtrn['y'] == 0][1])\n",
    "x_star = 3\n",
    "miu_star = sum(x_train) / (len(x_train) + 1 / a)\n",
    "alpha = b + len(x_train) / 2\n",
    "beta = c + 0.5 * (len(x_train) * np.var(x_train) + len(x_train) * ((sp.mean(x_train)) ** 2) / (1 + len(x_train)))\n",
    "N_star = 1 / (len(x_train) + 1 / a)\n",
    "value = sp.special.gamma(alpha + 0.5) / sp.special.gamma(alpha) * sp.sqrt(alpha / (beta * (N_star + 1)) / (sp.pi * 2 * alpha)) * sp.power(1 + ((alpha / (beta * (N_star + 1))) * ((x_star - miu_star)** 2)) / (2 * alpha), - alpha - 0.5)          \n",
    "print value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0039848174149395834"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.sqrt(alpha / (beta * (N_star + 1)) / (sp.pi * 2 * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14551098327797801"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.power(1 + ((alpha / (beta * (N_star + 1))) * ((x_star - miu_star)** 2)) / (2 * alpha), - alpha - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
